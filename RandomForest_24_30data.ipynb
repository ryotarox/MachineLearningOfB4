{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d02b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import datetime\n",
    "import time\n",
    "warnings.simplefilter('ignore')\n",
    "import math\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6cd48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-31 00:48:22.623507\n"
     ]
    }
   ],
   "source": [
    "status = pd.read_csv('../../../status.csv')\n",
    "\n",
    "#statusのyear, month, dayを結合してdatetime型に\n",
    "status['date'] = status['year'].astype(str) + '/' + status['month'].astype(str).str.zfill(2).astype(str) + '/' + status['day'].astype(str).str.zfill(2).astype(str) + '/' + status['hour'].astype(str).str.zfill(2).astype(str)\n",
    "status['date'] = pd.to_datetime(status['date'], format='%Y/%m/%d/%H', infer_datetime_format=True)\n",
    "\n",
    "#曜日を追加するための関数を定義\n",
    "def get_weekday_jp(dt):\n",
    "    w_list = ['月曜日', '火曜日', '水曜日', '木曜日', '金曜日', '土曜日', '日曜日']\n",
    "    return(w_list[dt.weekday()])\n",
    "\n",
    "#dateから曜日情報を取得\n",
    "status[\"weekday\"] = status[\"date\"].apply(get_weekday_jp)\n",
    "\n",
    "main_df = status[['date','hour', 'station_id', 'bikes_available', 'weekday', 'day']]\n",
    "\n",
    "#カテゴリ変数をダミー変数化\n",
    "main_df = pd.get_dummies(main_df)\n",
    "\n",
    "stationid_set = [0, 15, 32, 36, 38, 40, 43, 49, 54, 56] \n",
    "dt_now = datetime.datetime.now()\n",
    "\n",
    "print(dt_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b30a10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n"
     ]
    }
   ],
   "source": [
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_lag = train_X[train_X['date'] < '2013-10-01']['bikes_available']\n",
    "\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    \n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:720-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    \n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/Landom_train_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2013-09-30']['bikes_available']     \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    pred_lightgbm_test = []\n",
    "    len(pred_lightgbm_test)\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "\n",
    "        pred_lightgbm_test_lag_line = regr.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/Landom_test_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "    test.to_csv(test_file_name)\n",
    "    print(dt_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484a57d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n"
     ]
    }
   ],
   "source": [
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_lag = train_X[train_X['date'] < '2014-02-01']\n",
    "    train_lag = train_lag[train_lag['date'] >= '2014-01-01']['bikes_available']\n",
    "    train_learn = train_X[train_X['date'] < '2014-02-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2014-01-02']\n",
    "    \n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:744-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    \n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_file_name = \"Landom_24_predict/Landom_train_stationid\" + str(station_id) + \"_201401.csv\" \n",
    "    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-02-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2014-01-31']['bikes_available']     \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-02-08']\n",
    "    test = test[test['date'] >= '2014-02-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    pred_lightgbm_test = []\n",
    "    len(pred_lightgbm_test)\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "\n",
    "        pred_lightgbm_test_lag_line = regr.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/Landom_test_stationid\" + str(station_id) + \"_201401.csv\" \n",
    "    test.to_csv(test_file_name)\n",
    "    print(dt_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaebb3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n",
      "2022-01-11 07:07:21.929902\n"
     ]
    }
   ],
   "source": [
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_lag = train_X[train_X['date'] < '2014-06-01']\n",
    "    train_lag = train_lag[train_lag['date'] >= '2014-05-01']['bikes_available']\n",
    "    train_learn = train_X[train_X['date'] < '2014-06-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2014-05-02']\n",
    "    \n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:744-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    \n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/Landom_train_stationid\" + str(station_id) + \"_201405.csv\" \n",
    "    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-06-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2014-05-31']['bikes_available']     \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-06-08']\n",
    "    test = test[test['date'] >= '2014-06-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    pred_lightgbm_test = []\n",
    "    len(pred_lightgbm_test)\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "\n",
    "        pred_lightgbm_test_lag_line = regr.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/Landom_test_stationid\" + str(station_id) + \"_201405.csv\" \n",
    "    test.to_csv(test_file_name)\n",
    "    print(dt_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdb1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868433d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d242275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cca82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/nomal/Landom_train_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    pred_lightgbm_test = regr.predict(test_x)\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/nomal/Landom_test_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "    test.to_csv(test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3f4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_learn = train_X[train_X['date'] < '2014-02-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2014-01-02']\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/nomal/Landom_train_stationid\" + str(station_id) + \"_201401.csv\" \n",
    "    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-02-08']\n",
    "    test = test[test['date'] >= '2014-02-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    pred_lightgbm_test = regr.predict(test_x)\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/nomal/Landom_test_stationid\" + str(station_id) + \"_201401.csv\" \n",
    "    test.to_csv(test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1c2957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7183868885040283\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_learn = train_X[train_X['date'] < '2014-06-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2014-05-02']\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/nomal/Landom_train_stationid\" + str(station_id) + \"_201405.csv\" \n",
    "    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-06-08']\n",
    "    test = test[test['date'] >= '2014-06-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    pred_lightgbm_test = regr.predict(test_x)\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/nomal/Landom_test_stationid\" + str(station_id) + \"_201405.csv\" \n",
    "    test.to_csv(test_file_name)\n",
    "elapsed_time = time.time() - start\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a00033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8d51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1136f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9306e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6183626651763916\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/nomal/Landom_train_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "#    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    pred_lightgbm_test = regr.predict(test_x)\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/nomal/Landom_test_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "#    test.to_csv(test_file_name)\n",
    "elapsed_time = time.time() - start\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca571e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.19123601913452\n"
     ]
    }
   ],
   "source": [
    "#計測用2013年10月\n",
    "start = time.time()\n",
    "for station_id in stationid_set:\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    train_lag = train_X[train_X['date'] < '2013-10-01']['bikes_available']\n",
    "\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    \n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:720-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    \n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    predictions = regr.predict(train_learn_x)\n",
    "    train_learn['predict_24'] = predictions\n",
    "    train_file_name = \"Landom_24_predict/Landom_train_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "#    train_learn.to_csv(train_file_name)\n",
    "    \n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2013-09-30']['bikes_available']     \n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    pred_lightgbm_test = []\n",
    "    len(pred_lightgbm_test)\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "\n",
    "        pred_lightgbm_test_lag_line = regr.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1\n",
    "\n",
    "    test['predict_24'] = pred_lightgbm_test\n",
    "    test_file_name = \"Landom_24_predict/Landom_test_stationid\" + str(station_id) + \"_201309.csv\" \n",
    "#    test.to_csv(test_file_name)\n",
    "elapsed_time = time.time() - start\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482d181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
