{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMAXコード\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train = main_df[main_df['station_id'] == station_id]\n",
    "    #学習期間を指定\n",
    "    train = train[train['date'] < '2013-10-01']\n",
    "    train = train[train['date'] >= '2013-09-01']\n",
    "    #学習に不必要な説明変数の削除\n",
    "    train = train.drop(\"station_id\",axis=1)\n",
    "    train = train.set_index('date')\n",
    "    #目的変数以外を外部変数に設定\n",
    "    train_exog =  train.drop(\"bikes_available\",axis=1)\n",
    "    \n",
    "    #予測期間を指定した一つの地点のdataframeにしている\n",
    "    test = main_df[main_df['station_id'] == station_id]\n",
    "    #予測期間を指定\n",
    "    test = test[test['date'] <= '2013-10-08 00:00:00']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    test = test.set_index('date')\n",
    "    #予測に不必要な外部変数の削除\n",
    "    test_exog = test.drop(\"station_id\",axis=1)\n",
    "    test_exog =  test_exog.drop(\"bikes_available\",axis=1)\n",
    "    #トレンドに関するAR項の数:p\n",
    "    #トレンドに関する差分の回数:d\n",
    "    #トレンドに関するMA項の数:q\n",
    "    #季節変動に関するAR項の数:sp\n",
    "    #季節変動に関する差分の回数:sd\n",
    "    #季節変動に関するMA項の数:sq\n",
    "    p, d, q, sp, sd, sq = 24, 1, 24, 1, 1, 1\n",
    "    #季節変動の期間範囲を指定する項目数\n",
    "    seasonal = 48\n",
    "\n",
    "    # SARIMAXモデルで学習\n",
    "    result_sarima = SARIMAX(\n",
    "        endog = train[\"bikes_available\"], \n",
    "        exog = train_exog,\n",
    "        order=(p,d,q), \n",
    "        seasonal_order=(sp,sd,sq,seasonal), \n",
    "        enforce_stationarity = False, \n",
    "        enforce_invertibility = False\n",
    "    ).fit()\n",
    "    #学習したモデルで予測期間で予測する\n",
    "    predict_sarima = result_sarima.predict('2013-10-01', '2013-10-08', exog=test_exog, dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34723d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestコード(lag変数あり)\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    #lag変数用のdetaframeの準備\n",
    "    train_lag = train_X[train_X['date'] < '2013-10-01']['bikes_available']\n",
    "    #学習期間を指定\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    #学習期間の説明変数にlag変数を追加する\n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:720-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    #学習期間の目的変数を指定\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #RandomForestで学習\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    \n",
    "    #予測期間のlag変数用のdetaframeの準備\n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2013-09-30']['bikes_available']   \n",
    "    #予測期間を指定\n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    #予測期間の目的変数を設定\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #予測期間で1時点ずつ予測する\n",
    "    pred_lightgbm_test = []\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "        pred_lightgbm_test_lag_line = regr.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce323a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestコード(回帰分析)\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    #学習期間を指定\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    #学習期間の目的変数を指定\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #RandomForestで学習\n",
    "    regr = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "    regr.fit(train_learn_x, train_learn_y)\n",
    "    \n",
    "    #予測期間を指定\n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    #予測期間の目的変数を設定\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)  \n",
    "    #学習したモデルで予測\n",
    "    pred_lightgbm_test = regr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386ba95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2389b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMコード(lag変数あり)\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    #lag変数用のdetaframeの準備\n",
    "    train_lag = train_X[train_X['date'] < '2013-10-01']['bikes_available']\n",
    "    #学習期間を指定\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    #学習期間の説明変数にlag変数を追加する\n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:720-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    #学習期間の目的変数を指定\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    train_lightgbm_set = lgb.Dataset(train_learn_x, train_learn_y)\n",
    "    \n",
    "    #LightGBMで学習\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"verbose\" : -1\n",
    "    }\n",
    "    lgb_model_24 = lgb.train(\n",
    "        params = params,\n",
    "        train_set = train_lightgbm_set,\n",
    "        valid_sets = [train_lightgbm_set, train_lightgbm_set],\n",
    "        num_boost_round = 300,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=5\n",
    "    )\n",
    "    \n",
    "    #予測期間のlag変数用のdetaframeの準備\n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2013-09-30']['bikes_available']     \n",
    "    #予測期間を指定\n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    #予測期間の目的変数を設定\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #予測期間で1時点ずつ予測する\n",
    "    pred_lightgbm_test = []\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "        pred_lightgbm_test_lag_line = lgb_model_24.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfdddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMコード(回帰分析)\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    #学習期間を指定\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    #学習期間の目的変数を指定\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "\n",
    "    train_lightgbm_set = lgb.Dataset(train_learn_x, train_learn_y)\n",
    "    #LightGBMで学習\n",
    "    model = lgb.LGBMRegressor(objective='rmse', n_estimators = 300)\n",
    "    model.fit(train_learn_x, train_learn_y, eval_set=[(train_learn_x, train_learn_y), (train_learn_x, train_learn_y)], verbose=10)\n",
    "    \n",
    "    #予測期間を指定\n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    #予測期間の目的変数を設定\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    #学習したモデルで予測\n",
    "    pred_lightgbm_test = model.predict(test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74148776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd77be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoostコード(lag変数あり)\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    #lag変数用のdetaframeの準備\n",
    "    train_lag = train_X[train_X['date'] < '2013-10-01']['bikes_available']\n",
    "    #学習期間を指定\n",
    "    train_learn = train_X[train_X['date'] < '2013-10-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2013-09-02']\n",
    "    #学習期間の説明変数にlag変数を追加する\n",
    "    i = 1\n",
    "    while i < 25:\n",
    "        row_name = \"lag_\" + str(i) + \"hour\"\n",
    "        set = train_lag[24-i:720-i]\n",
    "        train_learn[row_name] = set.values\n",
    "        i += 1\n",
    "    i = 0    \n",
    "    #学習期間の目的変数を指定\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #XGBoostで学習\n",
    "    reg_mod = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.10,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=1, \n",
    "        max_depth=15,\n",
    "    )\n",
    "    reg_mod.fit(train_learn_x, train_learn_y) \n",
    "\n",
    "    #予測期間のlag変数用のdetaframeの準備\n",
    "    test_lag = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-01']\n",
    "    test_lag = test_lag[test_lag['date'] >= '2013-09-30']['bikes_available'] \n",
    "    #予測期間を指定\n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2013-10-08']\n",
    "    test = test[test['date'] >= '2013-10-01']\n",
    "    #予測期間の目的変数を設定\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #予測期間で1時点ずつ予測する\n",
    "    pred_lightgbm_test = []\n",
    "    i=0\n",
    "    while i < 168:\n",
    "        test_x_line = test_x[i:i+1]\n",
    "\n",
    "        lag = []\n",
    "        for j in pred_lightgbm_test:\n",
    "            lag.insert(0, j)\n",
    "\n",
    "        for k in range(24 - len(pred_lightgbm_test)):\n",
    "            lag.append(test_lag[23-k:24-k].values)\n",
    "        s = 1\n",
    "        while s < 25:\n",
    "            row_name = \"lag_\" + str(s) + \"hour\"\n",
    "            test_x_line[row_name] = lag[s-1]\n",
    "            s += 1\n",
    "\n",
    "        pred_lightgbm_test_lag_line = reg_mod.predict(test_x_line)\n",
    "        pred_lightgbm_test =np.append(pred_lightgbm_test, pred_lightgbm_test_lag_line)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGboostコード(回帰分析)\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train_X = main_df[main_df['station_id'] == station_id]\n",
    "    #学習期間を指定\n",
    "    train_learn = train_X[train_X['date'] < '2014-02-01']\n",
    "    train_learn = train_learn[train_learn['date'] >= '2014-01-02']\n",
    "    #学習期間の目的変数を指定\n",
    "    train_learn_y = train_learn[\"bikes_available\"]\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train_learn_x = train_learn.drop(\"station_id\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"date\",axis=1)\n",
    "    train_learn_x = train_learn_x.drop(\"bikes_available\",axis=1)    \n",
    "    \n",
    "    #XGBoostで学習\n",
    "    dtrain = xgb.DMatrix(train_learn_x, label=train_learn_y)\n",
    "    params = {\n",
    "        \"objective\" : \"reg:squarederror\",\n",
    "        \"eval_metric\" : \"rmse\"\n",
    "    }        \n",
    "    dtrain = xgb.DMatrix(train_learn_x, train_learn_y)\n",
    "    results_dict = {}\n",
    "    model = xgb.train(\n",
    "        params = params,\n",
    "        dtrain =  dtrain,\n",
    "        evals = [(dtrain, \"train\"), (dtrain, \"train\")],\n",
    "        num_boost_round = 300,\n",
    "        verbose_eval=50,\n",
    "        evals_result = results_dict\n",
    "    )\n",
    "    #予測期間の指定\n",
    "    test = main_df[main_df['station_id'] == station_id][main_df['date'] < '2014-02-08']\n",
    "    test = test[test['date'] >= '2014-02-01']\n",
    "    #予測期間の目的変数を設定\n",
    "    test_y = test[\"bikes_available\"]\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test_x = test.drop(\"station_id\",axis=1)\n",
    "    test_x = test_x.drop(\"date\",axis=1)\n",
    "    test_x = test_x.drop(\"bikes_available\",axis=1)    \n",
    "    #学習したモデルで予測\n",
    "    pred_lightgbm_test = model.predict(xgb.DMatrix(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff50696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTMコード\n",
    "for station_id in stationid_set:\n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    train = main_df[main_df['station_id'] == station_id]\n",
    "    #学習期間を指定\n",
    "    train = train[train['date'] < '2013-10-01']\n",
    "    train = train[train['date'] >= '2013-09-01']\n",
    "    #学習期間で不必要な説明変数の削除\n",
    "    train = train.drop(\"station_id\",axis=1)\n",
    "    \n",
    "    #指定した一つの地点のdataframeにしている\n",
    "    test = main_df[main_df['station_id'] == station_id]\n",
    "    #予測期間を指定\n",
    "    test = test[test['date'] <= '2013-10-08 00:00:00']\n",
    "    test = test[test['date'] >= '2013-09-30']\n",
    "    #予測期間で不必要な説明変数の削除\n",
    "    test = test.drop(\"station_id\",axis=1)\n",
    "\n",
    "    #今回LSTMモデルを使用するため、データを標準化\n",
    "    #特徴量を標準化するための変数\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #標準化された出力をもとにスケールに変換(inverse)するために必要な変数\n",
    "    scaler_for_inverse = MinMaxScaler(feature_range=(0, 1))\n",
    "    #0から1の範囲に値を正規化して配列に直しているのが下の2行\n",
    "    train_df_scale = scaler.fit_transform(train.iloc[:,2:])\n",
    "    bikes_available_scale = scaler_for_inverse.fit_transform(train[[\"bikes_available\"]])\n",
    "    \n",
    "    length = len(train_df_scale)\n",
    "    train = train_df_scale[0:length,:]\n",
    "\n",
    "    def create_dataset(dataset):\n",
    "        dataX = []\n",
    "        dataY = np.array([])\n",
    "\n",
    "        #trainまたはtestの行を計算している。\n",
    "        max_len = len(dataset)\n",
    "        for i in range(24,max_len):\n",
    "            xset = []\n",
    "            #trainまたはtestの列を繰り返しに入れている。\n",
    "            for j in range(1, dataset.shape[1]):\n",
    "                a = dataset[i-24:i, j]\n",
    "                xset.append(a)\n",
    "            #各行の正規化したバイク台数を取ってくる\n",
    "            temp_array = np.array(dataset[i:i+1,0])\n",
    "            #各行からバイク台数だけを取ってきたものをまとめている\n",
    "            dataY = np.concatenate([dataY,temp_array])\n",
    "            dataX.append(xset)\n",
    "            #dataYの形を変えてるだけ\n",
    "        dataY = dataY.reshape(-1,1)\n",
    "        return np.array(dataX), dataY \n",
    "\n",
    "    trainX, trainY = create_dataset(train)\n",
    "    #LSTMのモデルに入力用にデータの形を整形\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(trainX.shape[1],24)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "    \n",
    "    hist = model.fit(trainX, trainY, epochs=300, batch_size=5, verbose=2)\n",
    "    \n",
    "    #学習済みモデルで予測\n",
    "    train_predict = model.predict(trainX)\n",
    "    #スケールをもとに戻す\n",
    "    train_predict = scaler_for_inverse.inverse_transform(train_predict)\n",
    "\n",
    "    #今回LSTMモデルを使用するため、データを標準化\n",
    "    #特徴量を標準化するための変数\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #標準化された出力をもとにスケールに変換(inverse)するために必要な変数\n",
    "    scaler_for_inverse = MinMaxScaler(feature_range=(0, 1))\n",
    "    test_df_scale = scaler.fit_transform(test.iloc[:,2:])\n",
    "    bikes_available_scale = scaler_for_inverse.fit_transform(test[[\"bikes_available\"]])\n",
    "    \n",
    "    length = len(test_df_scale)\n",
    "    test = test_df_scale[0:length,:]\n",
    "    testX, testY = create_dataset(test)\n",
    "    #LSTMのモデルに入力用にデータの形を整形\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "    #学習済みモデルで予測\n",
    "    test_predict = model.predict(testX)\n",
    "    #スケールをもとに戻す\n",
    "    test_predict = scaler_for_inverse.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971adde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc530d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea0a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
